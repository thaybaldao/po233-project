{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pré-Processamento dos Dados\n",
    "\n",
    "## Título:\n",
    "\n",
    "**Predição de preço de imóveis**\n",
    "\n",
    "## Membros:\n",
    "\n",
    "*   Adrisson Rogério Samersla\n",
    "*   Nickolas Batista Mendonça Machado\n",
    "*   Thayna Pires Baldão\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Importando os pacotes necessários para a análise\n",
    "\n",
    "import os\n",
    "\n",
    "import pandas            as pd\n",
    "import geopandas         as gpd\n",
    "import numpy             as np\n",
    "import scipy             as sc\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn           as sns\n",
    "\n",
    "from google_drive_downloader import GoogleDriveDownloader as gdd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "\n",
    "import mapclassify\n",
    "\n",
    "pd.set_option('display.max_columns', None)  \n",
    "pd.set_option('display.expand_frame_repr', False)\n",
    "pd.reset_option('max_colwidth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Baixando o dataset\n",
    "\n",
    "dataset_dir = \"../dataset\"\n",
    "has_dataset_dir = os.path.isdir(dataset_dir)\n",
    "if (not has_dataset_dir):\n",
    "  # Link of dataset folder: \n",
    "  # https://drive.google.com/file/d/1S4rBgtuogAGr_WIcF-FIPaULfGlB9MRs/view?usp=sharing\n",
    "  gdd.download_file_from_google_drive(file_id='1S4rBgtuogAGr_WIcF-FIPaULfGlB9MRs',\n",
    "                                      dest_path='../dataset.zip',\n",
    "                                      showsize=True,\n",
    "                                      unzip=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Lendo a base de dados\n",
    "\n",
    "df = pd.read_csv(dataset_dir + '/dataset.csv')\n",
    "print(\"Formato dos dados: \", df.shape)\n",
    "print(\"#Exemplos: {}\".format(df.shape[0]))\n",
    "print(\"#Atributos: {}\".format(df.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Seleção Manual de Atributos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ignore_columns = [\n",
    "    'id',\n",
    "    'property_id',\n",
    "    'operation',\n",
    "    'place_name',\n",
    "    'place_with_parent_names',\n",
    "    'country_name',\n",
    "    'state_name',\n",
    "    'geonames_id',\n",
    "    'lat_lon',\n",
    "    'currency',\n",
    "    'floor',\n",
    "    'description',\n",
    "    'title',\n",
    "    'image_thumbnail',\n",
    "    'collected_on'\n",
    "]\n",
    "\n",
    "def manual_selection(dataset):\n",
    "    return dataset.drop(columns=ignore_columns)\n",
    "\n",
    "#filtered = manual_selection(df)\n",
    "# for col in ignore_columns:\n",
    "#     assert col not in manual_selection(df).columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Limpeza de dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminando Inconsistências"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Moedas Estrangeiras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.currency.astype('str').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def filter_currency(dataset):\n",
    "    positions = dataset['currency'] == 'BRL'\n",
    "    return dataset[positions]\n",
    "\n",
    "#df = filter_currency(df).currency.astype('str').value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Objetos Fora do Brasil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.state_name.astype('str').value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def filter_latlon(dataset):\n",
    "    data = dataset[['lat', 'lon']]\n",
    "\n",
    "    # data = data.dropna()\n",
    "    # points = gpd.points_from_xy(data.lon, data.lat, crs=map_df.crs)\n",
    "    # points = gpd.GeoSeries(points)\n",
    "    # positions_in = map_df.contains(points)\n",
    "\n",
    "    positions = data.lat.notna().squeeze() & data.lon.notna().squeeze()\n",
    "\n",
    "    lon_max = -30.0\n",
    "    lon_min = -80.0\n",
    "    lat_min = -40.0\n",
    "    lat_max = 10.0\n",
    "    return dataset.loc[\n",
    "        positions & \n",
    "        (dataset.state_name != \"Outros países\") &\n",
    "        ((data.lat > lat_min) & (data.lat < lat_max)) & \n",
    "        ((data.lon > lon_min) & (data.lon < lon_max))\n",
    "    ]\n",
    "\n",
    "#filter_latlon(df).state_name.astype('str').value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eliminando Outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def remove_outliers(dataset, cols):\n",
    "    Q1 = dataset[cols].quantile(0.25)\n",
    "    Q3 = dataset[cols].quantile(0.75)\n",
    "    IQR = Q3 - Q1\n",
    "    return dataset[~((dataset[cols] < (Q1 - 1.5 * IQR)) |(dataset[cols] > (Q3 + 1.5 * IQR))).any(axis=1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lidando com dados incompletos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `expenses`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fill_expenses(dataset):\n",
    "    dataset['expenses'].fillna(0.0, inplace=True)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `surface_total_in_m2` e `surface_covered_in_m2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fill_surface_total_with_surface_covered(dataset):\n",
    "    dataset['surface_total_in_m2'].fillna(dataset['surface_covered_in_m2'], inplace=True)\n",
    "    return dataset\n",
    "\n",
    "def fill_surface_covered_with_surface_total(dataset):\n",
    "    dataset['surface_covered_in_m2'].fillna(dataset['surface_total_in_m2'], inplace=True)\n",
    "    return dataset\n",
    "\n",
    "def fill_remaining_objects_without_surfaces(dataset):\n",
    "    dataset['surface_total_in_m2'].fillna(dataset['surface_total_in_m2'].mean(), inplace=True)\n",
    "    dataset['surface_covered_in_m2'].fillna(dataset['surface_covered_in_m2'].mean(), inplace=True)\n",
    "    return dataset\n",
    "\n",
    "def drop_remaining_objects_without_surfaces(dataset):\n",
    "    dataset.dropna(subset=['surface_total_in_m2'], how='all', inplace=True)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `rooms`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "def fill_rooms(dataset):\n",
    "    dataset['surface_category'] = pd.qcut(dataset['surface_covered_in_m2'],4)\n",
    "    dataset['rooms'] = dataset['rooms'].fillna(dataset.groupby('surface_category')['rooms'].transform('mean').round())\n",
    "    return dataset.drop(columns=['surface_category'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Transformando dados"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conversão simbólico-numérico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `property_type`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_property_type(dataset):\n",
    "    oe_style = OneHotEncoder()\n",
    "    oe_results =  oe_style.fit_transform(dataset[['property_type']])\n",
    "    dataset = dataset.join(pd.DataFrame(oe_results.toarray(), columns= oe_style.categories_))\n",
    "    dataset.rename(columns=lambda s : str(s).replace(\",\", \"\").replace(\"(\", \"\").replace(\")\", \"\").replace(\"\\'\", \"\") , inplace = True)\n",
    "    dataset = dataset.drop(columns=['property_type'])\n",
    "    return dataset[[c for c in dataset if c not in ['price']] + ['price']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `created_on`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_created_on(dataset):\n",
    "    ord_enc = OrdinalEncoder()\n",
    "    dataset['created_on'] = ord_enc.fit_transform(dataset[['created_on']])\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Normalização"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Por reescala"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_max_min(dataset, cols):\n",
    "    for feature in cols:\n",
    "        max_value = dataset[feature].max()\n",
    "        min_value = dataset[feature].min()\n",
    "        dataset[feature] = (dataset[feature] - min_value) / (max_value - min_value)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Por padronização"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardizate(dataset, cols):\n",
    "    for feature in cols:\n",
    "        dataset[feature] = (dataset[feature] - dataset[feature].mean()) / (dataset[feature].std())\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aplicando o Pré-Processamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"#Exemplos: {}\".format(df.shape[0]))\n",
    "print(\"#Atributos: {}\".format(df.shape[1]))\n",
    "df = filter_currency(df)\n",
    "df = filter_latlon(df)\n",
    "\n",
    "df = manual_selection(df)\n",
    "print(\"#Exemplos: {}\".format(df.shape[0]))\n",
    "print(\"#Atributos: {}\".format(df.shape[1]))\n",
    "df.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.isnull().sum()*100/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = fill_expenses(df)\n",
    "df = fill_surface_total_with_surface_covered(df)\n",
    "df = fill_surface_covered_with_surface_total(df)\n",
    "df = drop_remaining_objects_without_surfaces(df)\n",
    "df.isnull().sum()*100/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df = fill_rooms(df)\n",
    "df.isnull().sum()*100/df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cols = ['rooms']\n",
    "df = remove_outliers(df, cols)\n",
    "print(\"#Exemplos: {}\".format(df.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = convert_property_type(df)\n",
    "df = convert_created_on(df)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['created_on', 'lat', 'lon', 'rooms']\n",
    "df = normalize_max_min(df, cols)\n",
    "\n",
    "cols = ['surface_total_in_m2', 'surface_covered_in_m2', 'expenses']\n",
    "df = standardizate(df, cols)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.dtypes\n",
    "df.to_csv(dataset_dir + \"/preprocessed.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "metadata": {
   "interpreter": {
    "hash": "39a99e6402a5e3089e52d8af32288dc93e4162e81faf72116ca75d773f310577"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
